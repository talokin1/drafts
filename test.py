import numpy as np
import lightgbm as lgb
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split

# 1. –û—á–∏—Å—Ç–∫–∞ –≤—ñ–¥ "—Ç–µ—Ö–Ω—ñ—á–Ω–∏—Ö" –º—ñ–Ω—É—Å—ñ–≤ (–æ–≤–µ—Ä–¥—Ä–∞—Ñ—Ç—ñ–≤)
df['CURR_ACC'] = df['CURR_ACC'].clip(lower=0)

# –°—ñ—Ç–∫–∞ –¥–ª—è –ø–æ—à—É–∫—É —ñ–¥–µ–∞–ª—å–Ω–æ–≥–æ –≤–∞—Ä—ñ–∞–Ω—Ç—É
# –î–æ–¥–∞–≤ 10 (–º—ñ–π —Ñ–∞–≤–æ—Ä–∏—Ç) —ñ 50 (–±—ñ–ª—å—à –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∏–π)
thresholds = [5, 10, 25, 50] 

best_mae = float('inf')
best_threshold = 0
results = {}

print("–ü–æ—á–∏–Ω–∞—î–º–æ –ø–æ—à—É–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥—É...")

for t in thresholds:
    # –ö–†–û–ö A: –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è "–ß–∏ —î –∑–Ω–∞—á—É—â–∞ —Å—É–º–∞?"
    # 1 - —Ü–µ –∫–ª—ñ—î–Ω—Ç –∑ –≥—Ä–æ—à–∏–º–∞ (> t), 0 - –ø—É—Å—Ç–∏–π –∞–±–æ "—Å–º—ñ—Ç—Ç—î–≤–∏–π" –∑–∞–ª–∏—à–æ–∫
    y_class_temp = (df['CURR_ACC'] > t).astype(int)
    
    # –°—Ç—Ä–∞—Ç–∏—Ñ—ñ–∫–æ–≤–∞–Ω–∏–π —Å–ø–ª—ñ—Ç
    X_train, X_test, y_cls_train, y_cls_test = train_test_split(
        df.drop(columns=['CURR_ACC']), y_class_temp,
        test_size=0.2, random_state=42, stratify=y_class_temp
    )
    
    # –ö–†–û–ö B: –ù–∞–≤—á–∞–Ω–Ω—è –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∞
    clf = lgb.LGBMClassifier(n_estimators=200, random_state=42, class_weight='balanced', verbose=-1)
    clf.fit(X_train, y_cls_train, categorical_feature=cat_features)
    
    # –ö–†–û–ö C: –ù–∞–≤—á–∞–Ω–Ω—è –†–µ–≥—Ä–µ—Å–æ—Ä–∞ (–¢–Ü–õ–¨–ö–ò –Ω–∞ "–∂–∏–≤–∏—Ö" –∫–ª—ñ—î–Ω—Ç–∞—Ö –∑ —Ç—Ä–µ–π–Ω—É)
    mask_vip_train = y_cls_train == 1
    X_reg_train = X_train[mask_vip_train]
    
    # –í–∞–∂–ª–∏–≤–æ: –º–∏ –≤—á–∏–º–æ —Ä–µ–≥—Ä–µ—Å–æ—Ä –ø–µ—Ä–µ–¥–±–∞—á–∞—Ç–∏ —Ç–æ—á–Ω—É —Å—É–º—É
    # –ê–ª–µ –æ—Å–∫—ñ–ª—å–∫–∏ –º–∏ –≤—ñ–¥—Å—ñ–∫–ª–∏ < t, –¥–∞–Ω—ñ –±—É–¥—É—Ç—å —á–∏—Å—Ç—ñ—à–∏–º–∏
    y_reg_train_log = np.log1p(df.loc[X_reg_train.index, 'CURR_ACC'])
    
    reg = lgb.LGBMRegressor(n_estimators=200, random_state=42, verbose=-1)
    reg.fit(X_reg_train, y_reg_train_log, categorical_feature=cat_features)
    
    # –ö–†–û–ö D: –í–∞–ª—ñ–¥–∞—Ü—ñ—è (Two-Stage Prediction)
    # 1. –ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å
    prob_active = clf.predict_proba(X_test)[:, 1]
    
    # 2. –ü—Ä–æ–≥–Ω–æ–∑ —Å—É–º–∏ (–¥–ª—è –≤—Å—ñ—Ö, –ø–æ—Ç—ñ–º –∑–∞–Ω—É–ª–∏–º–æ)
    pred_log = reg.predict(X_test)
    pred_amount = np.expm1(pred_log)
    
    # 3. –ö–æ–º–±—ñ–Ω–∞—Ü—ñ—è (Soft Gating)
    # –§–æ—Ä–º—É–ª–∞: –ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å * –ü—Ä–æ–≥–Ω–æ–∑ —Å—É–º–∏
    # –¶–µ "–æ—á—ñ–∫—É–≤–∞–Ω–∞ –≤–∞—Ä—Ç—ñ—Å—Ç—å" (Expected Value)
    final_pred = prob_active * pred_amount
    
    # –†–∞—Ö—É—î–º–æ —Ä–µ–∞–ª—å–Ω–∏–π MAE
    y_true = df.loc[X_test.index, 'CURR_ACC']
    mae = mean_absolute_error(y_true, final_pred)
    
    results[t] = mae
    print(f"Threshold {t} –≥—Ä–Ω -> MAE: {mae:.2f}")
    
    if mae < best_mae:
        best_mae = mae
        best_threshold = t

print(f"\nüèÜ –ü–µ—Ä–µ–º–æ–∂–µ—Ü—å: {best_threshold} –≥—Ä–Ω (MAE: {best_mae:.2f})")